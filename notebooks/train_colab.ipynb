{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Costco Label OBB Detection — Training on Colab\n\nThis notebook trains a YOLOv26-OBB model to detect Costco price labels.\n\n**Runtime → Change runtime type → T4 GPU** before running."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Clone repo and set working directory\nimport os\n\nREPO_URL = \"https://github.com/ankurkhurana03/Label_extractor_costco.git\"\nREPO_DIR = \"/content/Label_extractor_costco\"\n\nif not os.path.exists(REPO_DIR):\n    !git clone $REPO_URL $REPO_DIR\nelse:\n    print(\"Repo already cloned, pulling latest...\")\n    !git -C $REPO_DIR pull\n\nos.chdir(REPO_DIR)\nprint(f\"Working directory: {os.getcwd()}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Install latest ultralytics (YOLO26 requires a recent version)\n!pip install -q --upgrade ultralytics albumentations\nimport ultralytics\nprint(f\"ultralytics version: {ultralytics.__version__}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from pathlib import Path\nfrom ultralytics import YOLO\n\nROOT = Path(\"/content/Label_extractor_costco\")\n\n# Verify dataset\nassert (ROOT / \"dataset.yaml\").exists(), f\"dataset.yaml not found in {ROOT}\"\ntrain_imgs = list((ROOT / \"dataset\" / \"images\" / \"train\").glob(\"*.*\"))\ntest_imgs = list((ROOT / \"dataset\" / \"images\" / \"test\").glob(\"*.*\"))\nprint(f\"ROOT: {ROOT}\")\nprint(f\"Train images: {len(train_imgs)} (before augmentation), Test images: {len(test_imgs)}\")"
  },
  {
   "cell_type": "code",
   "source": "# Offline augmentation: generate 4x copies of each labeled training image\n# This multiplies the dataset from ~64 labeled images to ~320, giving the\n# model more gradient updates per epoch and smoother learning.\n\nimport cv2\nimport numpy as np\nfrom pathlib import Path\nimport shutil\n\nMULTIPLIER = 4  # number of augmented copies per image\nIMG_DIR = ROOT / \"dataset\" / \"images\" / \"train\"\nLBL_DIR = ROOT / \"dataset\" / \"labels\" / \"train\"\n\nrng = np.random.default_rng(42)\n\ndef augment_image(img):\n    \"\"\"Apply random geometric + color augmentations to an image.\"\"\"\n    h, w = img.shape[:2]\n    out = img.copy()\n\n    # Random horizontal flip\n    if rng.random() > 0.5:\n        out = cv2.flip(out, 1)\n\n    # Random vertical flip\n    if rng.random() > 0.5:\n        out = cv2.flip(out, 0)\n\n    # Random rotation (-25 to +25 degrees)\n    angle = rng.uniform(-25, 25)\n    M = cv2.getRotationMatrix2D((w / 2, h / 2), angle, 1.0)\n    out = cv2.warpAffine(out, M, (w, h), borderMode=cv2.BORDER_REFLECT_101)\n\n    # Random brightness/contrast\n    alpha = rng.uniform(0.7, 1.3)  # contrast\n    beta = rng.uniform(-30, 30)     # brightness\n    out = np.clip(alpha * out.astype(np.float32) + beta, 0, 255).astype(np.uint8)\n\n    # Random HSV shift\n    hsv = cv2.cvtColor(out, cv2.COLOR_BGR2HSV).astype(np.float32)\n    hsv[:, :, 0] = (hsv[:, :, 0] + rng.uniform(-10, 10)) % 180\n    hsv[:, :, 1] = np.clip(hsv[:, :, 1] * rng.uniform(0.7, 1.3), 0, 255)\n    hsv[:, :, 2] = np.clip(hsv[:, :, 2] * rng.uniform(0.7, 1.3), 0, 255)\n    out = cv2.cvtColor(hsv.astype(np.uint8), cv2.COLOR_HSV2BGR)\n\n    # Random Gaussian blur\n    if rng.random() > 0.5:\n        ksize = rng.choice([3, 5])\n        out = cv2.GaussianBlur(out, (ksize, ksize), 0)\n\n    return out\n\ndef rotate_obb_points(points, angle_deg, cx, cy):\n    \"\"\"Rotate OBB polygon points around center (normalized coords).\"\"\"\n    angle = np.radians(-angle_deg)  # negative because cv2 rotates counterclockwise\n    cos_a, sin_a = np.cos(angle), np.sin(angle)\n    rotated = []\n    for x, y in points:\n        dx, dy = x - cx, y - cy\n        rx = cos_a * dx - sin_a * dy + cx\n        ry = sin_a * dx + cos_a * dy + cy\n        rotated.append((np.clip(rx, 0, 1), np.clip(ry, 0, 1)))\n    return rotated\n\ndef augment_label(label_path, h_flip, v_flip, angle):\n    \"\"\"Transform OBB label coordinates to match augmented image.\"\"\"\n    if not label_path.exists():\n        return \"\"\n    text = label_path.read_text().strip()\n    if not text:\n        return \"\"\n    lines = []\n    for line in text.splitlines():\n        parts = line.strip().split()\n        if len(parts) != 9:\n            continue\n        cls_id = parts[0]\n        coords = list(map(float, parts[1:]))\n        points = [(coords[i], coords[i+1]) for i in range(0, 8, 2)]\n\n        if h_flip:\n            points = [(1.0 - x, y) for x, y in points]\n        if v_flip:\n            points = [(x, 1.0 - y) for x, y in points]\n        if abs(angle) > 0.1:\n            points = rotate_obb_points(points, angle, 0.5, 0.5)\n\n        coord_str = \" \".join(f\"{x:.6f} {y:.6f}\" for x, y in points)\n        lines.append(f\"{cls_id} {coord_str}\")\n    return \"\\n\".join(lines)\n\n# Only augment labeled images (skip neg_ and synth_ prefixes)\nlabeled_imgs = sorted([\n    p for p in IMG_DIR.glob(\"*.*\")\n    if p.suffix.lower() in {\".jpg\", \".jpeg\", \".png\", \".webp\"}\n    and not p.name.startswith((\"neg_\", \"synth_\"))\n])\n\nprint(f\"Found {len(labeled_imgs)} labeled training images\")\nprint(f\"Generating {MULTIPLIER}x augmented copies...\")\n\ngenerated = 0\nfor img_path in labeled_imgs:\n    lbl_path = LBL_DIR / (img_path.stem + \".txt\")\n    img = cv2.imread(str(img_path))\n    if img is None:\n        continue\n\n    for i in range(MULTIPLIER):\n        # Track transforms for label adjustment\n        h_flip = rng.random() > 0.5\n        v_flip = rng.random() > 0.5\n        angle = rng.uniform(-25, 25)\n\n        # Apply transforms to image\n        h, w = img.shape[:2]\n        out = img.copy()\n        if h_flip:\n            out = cv2.flip(out, 1)\n        if v_flip:\n            out = cv2.flip(out, 0)\n        M = cv2.getRotationMatrix2D((w / 2, h / 2), angle, 1.0)\n        out = cv2.warpAffine(out, M, (w, h), borderMode=cv2.BORDER_REFLECT_101)\n\n        # Color augmentation (doesn't affect labels)\n        alpha = rng.uniform(0.7, 1.3)\n        beta = rng.uniform(-30, 30)\n        out = np.clip(alpha * out.astype(np.float32) + beta, 0, 255).astype(np.uint8)\n        hsv = cv2.cvtColor(out, cv2.COLOR_BGR2HSV).astype(np.float32)\n        hsv[:, :, 0] = (hsv[:, :, 0] + rng.uniform(-10, 10)) % 180\n        hsv[:, :, 1] = np.clip(hsv[:, :, 1] * rng.uniform(0.7, 1.3), 0, 255)\n        hsv[:, :, 2] = np.clip(hsv[:, :, 2] * rng.uniform(0.7, 1.3), 0, 255)\n        out = cv2.cvtColor(hsv.astype(np.uint8), cv2.COLOR_HSV2BGR)\n        if rng.random() > 0.5:\n            out = cv2.GaussianBlur(out, (rng.choice([3, 5]),) * 2, 0)\n\n        # Save augmented image and label\n        aug_name = f\"aug{i}_{img_path.stem}\"\n        cv2.imwrite(str(IMG_DIR / f\"{aug_name}.jpg\"), out)\n        aug_label = augment_label(lbl_path, h_flip, v_flip, angle)\n        (LBL_DIR / f\"{aug_name}.txt\").write_text(aug_label)\n        generated += 1\n\ntotal = len(list(IMG_DIR.glob(\"*.*\")))\nprint(f\"Generated {generated} augmented images\")\nprint(f\"Total training images now: {total}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Train with improved hyperparameters\nmodel = YOLO(\"yolo26n-obb.pt\")\n\nresults = model.train(\n    data=str(ROOT / \"dataset.yaml\"),\n    epochs=300,\n    imgsz=640,\n    batch=16,         # T4 has 16GB VRAM — can handle batch=16\n    patience=50,\n    device=0,         # GPU 0\n    project=str(ROOT / \"runs\"),\n    name=\"costco_label_obb\",\n    exist_ok=True,\n    # Augmentation tuned for small dataset\n    mosaic=1.0,\n    flipud=0.5,\n    fliplr=0.5,\n    degrees=30.0,\n    scale=0.5,\n    translate=0.2,\n    mixup=0.3,\n    copy_paste=0.3,\n    # Color augmentation\n    hsv_h=0.015,\n    hsv_s=0.7,\n    hsv_v=0.4,\n    # Regularization\n    weight_decay=0.001,\n    dropout=0.1,\n)\n\nprint(f\"\\nBest model: {ROOT / 'runs' / 'costco_label_obb' / 'weights' / 'best.pt'}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View training curves\n",
    "from IPython.display import Image, display\n",
    "\n",
    "results_img = ROOT / \"runs\" / \"costco_label_obb\" / \"results.png\"\n",
    "if results_img.exists():\n",
    "    display(Image(filename=str(results_img), width=800))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate on test set\n",
    "best = YOLO(str(ROOT / \"runs\" / \"costco_label_obb\" / \"weights\" / \"best.pt\"))\n",
    "metrics = best.val(data=str(ROOT / \"dataset.yaml\"), device=0)\n",
    "print(f\"\\nmAP50: {metrics.box.map50:.4f}\")\n",
    "print(f\"mAP50-95: {metrics.box.map:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run predictions on a few test images\n",
    "import random\n",
    "\n",
    "test_dir = ROOT / \"dataset\" / \"images\" / \"test\"\n",
    "sample_imgs = random.sample(list(test_dir.glob(\"*.*\")), min(6, len(list(test_dir.glob(\"*.*\")))))\n",
    "\n",
    "preds = best.predict(source=sample_imgs, imgsz=640, device=0, save=True,\n",
    "                      project=str(ROOT / \"runs\"), name=\"predict_samples\", exist_ok=True)\n",
    "\n",
    "# Display predictions\n",
    "pred_dir = ROOT / \"runs\" / \"predict_samples\"\n",
    "for img_path in sorted(pred_dir.glob(\"*.jpg\"))[:6]:\n",
    "    display(Image(filename=str(img_path), width=500))\n",
    "    print(img_path.name)\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "source": "# Sanity check: model should NOT fire on blank/noise images\nimport numpy as np\n\ndef count_detections(results, conf=0.5):\n    count, max_conf = 0, 0.0\n    for r in results:\n        if r.obb is not None and len(r.obb):\n            confs = r.obb.conf.cpu().numpy()\n            count += len(confs[confs >= conf])\n            if len(confs): max_conf = max(max_conf, float(confs.max()))\n    return count, max_conf\n\nprint(\"Synthetic sanity checks (conf=0.5):\")\nfor name, img in [\n    (\"Blank white\", np.ones((640,640,3), dtype=np.uint8)*255),\n    (\"Blank black\", np.zeros((640,640,3), dtype=np.uint8)),\n    (\"Random noise\", np.random.default_rng(42).integers(0,256,(640,640,3), dtype=np.uint8)),\n]:\n    res = best.predict(img, conf=0.5, verbose=False)\n    n, mc = count_detections(res)\n    status = \"PASS\" if n == 0 else \"FAIL\"\n    print(f\"  [{status}] {name}: {n} detections (max conf {mc:.3f})\")\n\n# Real test images summary\ntest_imgs = sorted(test_dir.glob(\"*.*\"))\ndetected = 0\nfor p in test_imgs:\n    res = best.predict(str(p), conf=0.5, verbose=False)\n    n, _ = count_detections(res)\n    if n > 0: detected += 1\nprint(f\"\\nReal test set: {detected}/{len(test_imgs)} images had detections ({detected/len(test_imgs)*100:.0f}%)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the best model\n",
    "from google.colab import files\n",
    "\n",
    "best_pt = ROOT / \"runs\" / \"costco_label_obb\" / \"weights\" / \"best.pt\"\n",
    "files.download(str(best_pt))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}